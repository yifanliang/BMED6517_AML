{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import sklearn as sk \n",
    "import numpy as np \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   1_FL1 Log  1_FL2 Log  1_FL3 Log  1_FL4 Log  1_FL5 Log  2_FL1 Log  \\\n",
       "0   0.205182   0.202277   0.589269   0.181832   0.161980   0.355550   \n",
       "1   0.281149   0.259472   0.492262   0.190994   0.167108   0.331801   \n",
       "2   0.278798   0.249169   0.542159   0.179060   0.162542   0.432686   \n",
       "3   0.241633   0.241526   0.499962   0.185286   0.177292   0.456296   \n",
       "4   0.303876   0.269966   0.547477   0.224098   0.170734   0.434227   \n",
       "\n",
       "   2_FL2 Log  2_FL3 Log  2_FL4 Log  2_FL5 Log  ...  8_FL5 Log    1_Size  \\\n",
       "0   0.376491   0.588194   0.178982   0.179637  ...   0.160188  0.732274   \n",
       "1   0.359391   0.489106   0.171462   0.186648  ...   0.161918  0.498556   \n",
       "2   0.463741   0.551797   0.180887   0.198905  ...   0.173292  0.553562   \n",
       "3   0.467985   0.503338   0.187750   0.191374  ...   0.164838  0.570285   \n",
       "4   0.446661   0.548693   0.239077   0.197856  ...   0.161466  0.813479   \n",
       "\n",
       "     2_Size    3_Size    4_Size    5_Size    6_Size    7_Size    8_Size  \\\n",
       "0  0.668522  0.707437  0.697957  0.740072  0.731966  0.721269  0.727084   \n",
       "1  0.450812  0.486406  0.443796  0.514050  0.509004  0.505540  0.560941   \n",
       "2  0.602390  0.598361  0.588802  0.625902  0.635771  0.634529  0.652307   \n",
       "3  0.543560  0.544120  0.561114  0.574668  0.599861  0.568463  0.613726   \n",
       "4  0.791529  0.824629  0.799338  0.861672  0.876643  0.877821  0.887210   \n",
       "\n",
       "    Label  \n",
       "0  normal  \n",
       "1  normal  \n",
       "2  normal  \n",
       "3  normal  \n",
       "4     aml  \n",
       "\n",
       "[5 rows x 49 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1_FL1 Log</th>\n      <th>1_FL2 Log</th>\n      <th>1_FL3 Log</th>\n      <th>1_FL4 Log</th>\n      <th>1_FL5 Log</th>\n      <th>2_FL1 Log</th>\n      <th>2_FL2 Log</th>\n      <th>2_FL3 Log</th>\n      <th>2_FL4 Log</th>\n      <th>2_FL5 Log</th>\n      <th>...</th>\n      <th>8_FL5 Log</th>\n      <th>1_Size</th>\n      <th>2_Size</th>\n      <th>3_Size</th>\n      <th>4_Size</th>\n      <th>5_Size</th>\n      <th>6_Size</th>\n      <th>7_Size</th>\n      <th>8_Size</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.205182</td>\n      <td>0.202277</td>\n      <td>0.589269</td>\n      <td>0.181832</td>\n      <td>0.161980</td>\n      <td>0.355550</td>\n      <td>0.376491</td>\n      <td>0.588194</td>\n      <td>0.178982</td>\n      <td>0.179637</td>\n      <td>...</td>\n      <td>0.160188</td>\n      <td>0.732274</td>\n      <td>0.668522</td>\n      <td>0.707437</td>\n      <td>0.697957</td>\n      <td>0.740072</td>\n      <td>0.731966</td>\n      <td>0.721269</td>\n      <td>0.727084</td>\n      <td>normal</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.281149</td>\n      <td>0.259472</td>\n      <td>0.492262</td>\n      <td>0.190994</td>\n      <td>0.167108</td>\n      <td>0.331801</td>\n      <td>0.359391</td>\n      <td>0.489106</td>\n      <td>0.171462</td>\n      <td>0.186648</td>\n      <td>...</td>\n      <td>0.161918</td>\n      <td>0.498556</td>\n      <td>0.450812</td>\n      <td>0.486406</td>\n      <td>0.443796</td>\n      <td>0.514050</td>\n      <td>0.509004</td>\n      <td>0.505540</td>\n      <td>0.560941</td>\n      <td>normal</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.278798</td>\n      <td>0.249169</td>\n      <td>0.542159</td>\n      <td>0.179060</td>\n      <td>0.162542</td>\n      <td>0.432686</td>\n      <td>0.463741</td>\n      <td>0.551797</td>\n      <td>0.180887</td>\n      <td>0.198905</td>\n      <td>...</td>\n      <td>0.173292</td>\n      <td>0.553562</td>\n      <td>0.602390</td>\n      <td>0.598361</td>\n      <td>0.588802</td>\n      <td>0.625902</td>\n      <td>0.635771</td>\n      <td>0.634529</td>\n      <td>0.652307</td>\n      <td>normal</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.241633</td>\n      <td>0.241526</td>\n      <td>0.499962</td>\n      <td>0.185286</td>\n      <td>0.177292</td>\n      <td>0.456296</td>\n      <td>0.467985</td>\n      <td>0.503338</td>\n      <td>0.187750</td>\n      <td>0.191374</td>\n      <td>...</td>\n      <td>0.164838</td>\n      <td>0.570285</td>\n      <td>0.543560</td>\n      <td>0.544120</td>\n      <td>0.561114</td>\n      <td>0.574668</td>\n      <td>0.599861</td>\n      <td>0.568463</td>\n      <td>0.613726</td>\n      <td>normal</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.303876</td>\n      <td>0.269966</td>\n      <td>0.547477</td>\n      <td>0.224098</td>\n      <td>0.170734</td>\n      <td>0.434227</td>\n      <td>0.446661</td>\n      <td>0.548693</td>\n      <td>0.239077</td>\n      <td>0.197856</td>\n      <td>...</td>\n      <td>0.161466</td>\n      <td>0.813479</td>\n      <td>0.791529</td>\n      <td>0.824629</td>\n      <td>0.799338</td>\n      <td>0.861672</td>\n      <td>0.876643</td>\n      <td>0.877821</td>\n      <td>0.887210</td>\n      <td>aml</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 49 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "#read in the excel training set\n",
    "df = pd.read_csv('training_with_size_ratio.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the test and label by dropping the columns in the dataframes\n",
    "x = df.drop(['Label'], axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "#test train split. 20 percent of the data(30 samples) will be used to test our predictions\n",
    "trainX, testX, trainY, testY = train_test_split(x, y, test_size = 0.2)"
   ]
  }
 ]
}